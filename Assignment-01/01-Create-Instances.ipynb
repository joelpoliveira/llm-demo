{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ijson\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_learning_instances_from_txt(source, out, end_of_paragraph=\"<|endoftext|>\"):\n",
    "    n_lines = 0\n",
    "    with open(source, 'r', encoding=\"utf-8\") as f_in:\n",
    "        for line in f_in: n_lines += 1\n",
    "     \n",
    "     \n",
    "    with open(source, 'r', encoding=\"utf-8\") as f_in:\n",
    "        f_out = open(out, 'w', encoding=\"utf-8\")\n",
    "\n",
    "        data = []\n",
    "        current_line = \"\"\n",
    "        for line in tqdm(f_in, total=n_lines):\n",
    "            if line.strip().strip(\"\\n\") == end_of_paragraph:\n",
    "                current_line+= end_of_paragraph\n",
    "                data.append(current_line)\n",
    "                current_line = \"\"\n",
    "            else:\n",
    "                current_line += line.strip()\n",
    "            \n",
    "        json.dump(data, f_out, ensure_ascii=False)            \n",
    "        f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15600057/15600057 [00:19<00:00, 804090.72it/s]\n"
     ]
    }
   ],
   "source": [
    "source = \"data/TinyStoriesV2-GPT4-train.txt\"\n",
    "dest = \"data/train.json\"\n",
    "\n",
    "create_learning_instances_from_txt(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157832/157832 [00:00<00:00, 665988.66it/s]\n"
     ]
    }
   ],
   "source": [
    "source = \"data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "dest = \"data/valid.json\"\n",
    "\n",
    "create_learning_instances_from_txt(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_examples(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f_in:\n",
    "        items = ijson.items(f_in, 'item')\n",
    "        return sum(1 for _ in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2717699, 27630)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_examples(\"data/train.json\"), count_examples(\"data/valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f_in:\n",
    "        return json.load(f_in)\n",
    "    \n",
    "def sample_examples(examples, percentage):\n",
    "    n = len(examples)\n",
    "    sample_size = int(n * percentage)\n",
    "    indices = np.random.choice(n, sample_size, replace=False)\n",
    "    \n",
    "    return [examples[i] for i in indices]\n",
    "\n",
    "def dump_json(examples, file_path):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as f_out:\n",
    "        json.dump(examples, f_out, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271769\n"
     ]
    }
   ],
   "source": [
    "p=0.1\n",
    "sampled_train_file = \"data/train-sampled.json\"\n",
    "train_examples = sample_examples(\n",
    "    load_examples(\"data/train.json\"),\n",
    "    p\n",
    ")\n",
    "print(len(train_examples))\n",
    "dump_json(train_examples, sampled_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381\n"
     ]
    }
   ],
   "source": [
    "sample_test_file = \"data/valid-sampled.json\"\n",
    "test_examples = sample_examples(\n",
    "    load_examples(\"data/valid.json\"),\n",
    "    p\n",
    ")\n",
    "print(len(test_examples))\n",
    "dump_json(test_examples, sample_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.json\", 'r', encoding=\"utf-8\") as f_in:\n",
    "    d = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271769\n",
      "27630\n"
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "with open(\"data/train-sampled.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(sum(1 for _ in ijson.items(f, \"item\")))\n",
    "\n",
    "with open(\"data/valid.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(sum(1 for _ in ijson.items(f, \"item\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
