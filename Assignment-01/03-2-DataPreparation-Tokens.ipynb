{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zlib\n",
    "import json\n",
    "import ijson\n",
    "import torch\n",
    "import tables\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "MAX_SEQ_LEN = 128+1\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"models/tokenizer.json\", \n",
    "    pad_token=\"[PAD]\", \n",
    "    unk_token=\"[UNK]\", \n",
    "    max_len=MAX_SEQ_LEN,\n",
    "    add_prefix_space=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokens_subsequences(\n",
    "        source,\n",
    "        dest,\n",
    "        tokenizer,\n",
    "        window_size,\n",
    "        stride,\n",
    "        compress=False\n",
    "):\n",
    "    with open(source, \"r\", encoding=\"utf-8\") as f_in:\n",
    "        data_in = json.load(f_in)\n",
    "\n",
    "    data_out = []\n",
    "    for story in tqdm(data_in):\n",
    "        tokens = tokenizer(\n",
    "            story,\n",
    "            return_special_tokens_mask=False,\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "            max_length=window_size,\n",
    "            padding=\"max_length\",\n",
    "            return_overflowing_tokens=True,\n",
    "            stride=stride,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        data_out.append(\n",
    "            tokens[\"input_ids\"] * tokens[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "    data_out = torch.cat(data_out)\n",
    "    \n",
    "    if compress:\n",
    "        output_bytes = io.BytesIO()\n",
    "        torch.save(data_out, output_bytes)\n",
    "\n",
    "        compressed_bytes = zlib.compress(output_bytes.getvalue())        \n",
    "        with open(f\"{dest}.zlib\", \"wb\") as f_out:\n",
    "            f_out.write(compressed_bytes)    \n",
    "    else:\n",
    "        torch.save(data_out, f\"{dest}\", pickle_protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135884/135884 [08:51<00:00, 255.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3550385, 129])\n"
     ]
    }
   ],
   "source": [
    "souce = \"data/train-sampled.json\"\n",
    "dest = \"data/train-sampled.pt\"\n",
    "save_tokens_subsequences(\n",
    "    souce, \n",
    "    dest, \n",
    "    tokenizer, \n",
    "    window_size=MAX_SEQ_LEN,\n",
    "    stride=MAX_SEQ_LEN - 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1381/1381 [00:17<00:00, 80.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139577, 129])\n"
     ]
    }
   ],
   "source": [
    "souce = \"data/valid-sampled.json\"\n",
    "dest = \"data/valid-sampled.pt\"\n",
    "save_tokens_subsequences(\n",
    "    souce, \n",
    "    dest, \n",
    "    tokenizer, \n",
    "    window_size=MAX_SEQ_LEN,\n",
    "    stride=MAX_SEQ_LEN - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_token_subsequences_to_hdf5(\n",
    "    source:str,\n",
    "    dest:str,\n",
    "    tokenizer,\n",
    "    compression:tables.Filters,\n",
    "    window_size:int,\n",
    "    stride:int,\n",
    "    name:str=\"data\",\n",
    "):        \n",
    "    with open(source, \"r\", encoding=\"utf-8\") as f_in:\n",
    "        n_stories = len(list(ijson.items(f_in, \"item\")))\n",
    "\n",
    "    with open(source, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "        tables.open_file(f\"{dest}.h5\", \"w\", filters=compression) as h5_out:\n",
    "        data_iter = ijson.items(f_in, \"item\")\n",
    "        data_out = h5_out.create_earray(\n",
    "            h5_out.root,\n",
    "            atom=tables.Int64Atom(),\n",
    "            shape=(0, window_size),\n",
    "            name=name,\n",
    "            expectedrows=5,\n",
    "            filters=compression\n",
    "        )\n",
    "\n",
    "        for story in tqdm(data_iter, total=n_stories):\n",
    "            tokens = tokenizer(\n",
    "                story,\n",
    "                return_special_tokens_mask=False,\n",
    "                truncation=True,\n",
    "                add_special_tokens=False,\n",
    "                max_length=window_size,\n",
    "                padding=\"max_length\",\n",
    "                return_overflowing_tokens=True,\n",
    "                stride=stride,\n",
    "                return_tensors=\"np\"\n",
    "            )\n",
    "\n",
    "            data_out.append(\n",
    "                tokens[\"input_ids\"] * tokens[\"attention_mask\"]\n",
    "            )\n",
    "\n",
    "        data_out.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135884/135884 [12:53<00:00, 175.61it/s]\n"
     ]
    }
   ],
   "source": [
    "souce = \"data/train-sampled.json\"\n",
    "dest = \"data/train-sampled\"\n",
    "save_token_subsequences_to_hdf5(\n",
    "    souce, \n",
    "    dest, \n",
    "    tokenizer, \n",
    "    compression=tables.Filters(complevel=1, complib=\"blosc2\"),\n",
    "    window_size=MAX_SEQ_LEN,\n",
    "    stride=MAX_SEQ_LEN - 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TinyStoriesTokensLoader(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path:str,\n",
    "        max_seq_len:int,\n",
    "        device=\"cpu\",\n",
    "        lazy_load=False,\n",
    "    ):\n",
    "        super(TinyStoriesTokensLoader, self).__init__()\n",
    "        self.max_seq_len = max_seq_len,\n",
    "        self.device = device\n",
    "\n",
    "        self._load_data(file_path, lazy_load)\n",
    "\n",
    "    def _load_data(self, file_path:str, lazy_load:bool):\n",
    "        self.data = torch.load(file_path, mmap=lazy_load)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx].to(self.device)\n",
    "        return tokens[:-1], tokens[1:]       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_a = DataLoader(\n",
    "    TinyStoriesTokensLoader(\n",
    "        \"data/train-sampled.pt\",\n",
    "        MAX_SEQ_LEN,\n",
    "        device=\"cuda\",\n",
    "        lazy_load=True,\n",
    "    ),\n",
    "    batch_size=512,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.52s\n",
      "Average = 0.10s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "n_iters = 5\n",
    "t = time()\n",
    "for i, _ in enumerate(ld_a):\n",
    "    if i==n_iters:\n",
    "        break\n",
    "    \n",
    "print(f\"Time taken: {time() - t:.2f}s\")\n",
    "print(f\"Average = {(time() - t) / n_iters:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TinyStoriesTokensHDF5Loader(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path:str,\n",
    "        max_seq_len:int,\n",
    "        compression:tables.Filters,\n",
    "        name:str=\"data\",\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super(TinyStoriesTokensHDF5Loader, self).__init__()\n",
    "        self.max_seq_len = max_seq_len,\n",
    "        self.device = device\n",
    "\n",
    "        self._load_data(file_path, compression, name)\n",
    "\n",
    "    def _load_data(self, file_path:str, compression:tables.Filters, name:str):\n",
    "        self.file = tables.open_file(file_path, mode=\"r\", filters=compression)\n",
    "        self.data = self.file.root[name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = torch.from_numpy(self.data[idx]).to(self.device, torch.long)\n",
    "        return tokens[:-1], tokens[1:]       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_b = DataLoader(\n",
    "    TinyStoriesTokensHDF5Loader(\n",
    "        \"data/train-sampled.h5\",\n",
    "        MAX_SEQ_LEN,\n",
    "        device=\"cuda\",\n",
    "        compression=tables.Filters(complevel=1, complib=\"blosc2\")\n",
    "    ),\n",
    "    batch_size=512,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 47.62s\n",
      "Average = 4.76s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "n_iters = 10\n",
    "t = time()\n",
    "for i, _ in enumerate(ld_b):\n",
    "    if i==n_iters:\n",
    "        break\n",
    "    \n",
    "print(f\"Time taken: {time() - t:.2f}s\")\n",
    "print(f\"Average = {(time() - t) / n_iters:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016007423400878906\n",
      "1.6069536209106445\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "next(iter(ld_a))\n",
    "print(time() - t)\n",
    "\n",
    "t = time()\n",
    "next(iter(ld_b))\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
